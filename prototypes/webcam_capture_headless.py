#!/usr/bin/env python3
"""
PROTOTYPE TYPE: THROWAWAY
PURPOSE: Test webcam capture performance with resource monitoring (HEADLESS)
EVIDENCE TARGET: CPU <15%, GPU <20%, RAM <300MB, Latency <100ms

This is a headless version that runs without GUI display for pure performance testing.
Run: python webcam_capture_headless.py
"""

import cv2
import numpy as np
import time
import psutil
import os
import sys
from collections import deque
from dataclasses import dataclass
from typing import Tuple, Optional
import threading


@dataclass
class PerformanceMetrics:
    """Performance metrics tracking"""
    fps: float = 0.0
    cpu_percent: float = 0.0
    memory_mb: float = 0.0
    frame_latency_ms: float = 0.0
    dropped_frames: int = 0
    resolution: Tuple[int, int] = (1280, 720)


class ResourceMonitor:
    """Monitor system resources"""
    
    def __init__(self, pid: int):
        self.pid = pid
        self.process = psutil.Process(pid)
        self.cpu_history = deque(maxlen=30)
        self.memory_history = deque(maxlen=30)
        
    def get_metrics(self) -> dict:
        """Get current resource usage"""
        try:
            cpu_percent = self.process.cpu_percent(interval=0.1)
            memory_info = self.process.memory_info()
            memory_mb = memory_info.rss / 1024 / 1024
            
            self.cpu_history.append(cpu_percent)
            self.memory_history.append(memory_mb)
            
            return {
                'cpu_percent': cpu_percent,
                'cpu_avg': np.mean(self.cpu_history) if self.cpu_history else 0,
                'memory_mb': memory_mb,
                'memory_peak': max(self.memory_history) if self.memory_history else 0
            }
        except:
            return {'cpu_percent': 0, 'cpu_avg': 0, 'memory_mb': 0, 'memory_peak': 0}


class HeadlessWebcamCapture:
    """Headless adaptive webcam capture for performance testing"""
    
    # Resolution presets (width, height)
    RESOLUTIONS = {
        '720p': (1280, 720),
        '480p': (640, 480),
        '360p': (480, 360)
    }
    
    def __init__(self, device_id: int = 0):
        self.device_id = device_id
        self.cap = None
        self.current_resolution = '720p'
        self.target_fps = 30
        
        # Performance tracking
        self.metrics = PerformanceMetrics()
        self.resource_monitor = ResourceMonitor(os.getpid())
        self.frame_times = deque(maxlen=30)
        self.dropped_frames = 0
        self.total_frames = 0
        
        # Throttling parameters
        self.skip_frames = 0
        self.quality_level = 2  # 0=360p, 1=480p, 2=720p
        
    def initialize(self) -> bool:
        """Initialize camera with optimal settings"""
        print(f"üé• Initializing webcam (device {self.device_id})...")
        
        # Try DirectShow on Windows for better performance
        if sys.platform == 'win32':
            self.cap = cv2.VideoCapture(self.device_id, cv2.CAP_DSHOW)
        else:
            self.cap = cv2.VideoCapture(self.device_id)
        
        if not self.cap.isOpened():
            print("‚ùå ERROR: Could not open webcam")
            print("   Make sure your webcam is connected and not in use by another app")
            return False
        
        # Set initial resolution
        self._set_resolution(self.current_resolution)
        
        # Set buffer size to reduce latency
        self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
        
        # Set FPS
        self.cap.set(cv2.CAP_PROP_FPS, self.target_fps)
        
        # Get actual settings
        actual_width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        actual_height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        actual_fps = self.cap.get(cv2.CAP_PROP_FPS)
        
        print(f"‚úÖ Camera initialized: {actual_width}x{actual_height} @ {actual_fps:.1f} FPS")
        return True
    
    def _set_resolution(self, resolution: str):
        """Set camera resolution"""
        width, height = self.RESOLUTIONS[resolution]
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
        self.current_resolution = resolution
        self.metrics.resolution = (width, height)
    
    def _adjust_quality(self, cpu_percent: float, memory_mb: float):
        """Dynamically adjust quality based on resource usage"""
        # CPU thresholds
        if cpu_percent > 20:  # Above target
            if self.quality_level > 0:
                self.quality_level -= 1
                resolutions = list(self.RESOLUTIONS.keys())
                self._set_resolution(resolutions[self.quality_level])
                print(f"  ‚¨á Downgrading to {self.current_resolution} (CPU: {cpu_percent:.1f}%)")
        elif cpu_percent < 10 and self.quality_level < 2:
            self.quality_level += 1
            resolutions = list(self.RESOLUTIONS.keys())
            self._set_resolution(resolutions[self.quality_level])
            print(f"  ‚¨Ü Upgrading to {self.current_resolution} (CPU: {cpu_percent:.1f}%)")
        
        # Frame skipping based on load
        if cpu_percent > 15:
            self.skip_frames = 1  # Skip every other frame
        elif cpu_percent > 20:
            self.skip_frames = 2  # Skip 2 out of 3 frames
        else:
            self.skip_frames = 0  # No skipping
        
        # Memory check
        if memory_mb > 300:
            print(f"  ‚ö† Memory usage high: {memory_mb:.1f} MB")
            import gc
            gc.collect()
    
    def capture_frame(self) -> Optional[np.ndarray]:
        """Capture a single frame with timing"""
        start_time = time.perf_counter()
        
        # Skip frames if needed
        for _ in range(self.skip_frames):
            self.cap.grab()  # Just grab without decoding
            self.dropped_frames += 1
        
        ret, frame = self.cap.read()
        
        if not ret:
            return None
        
        # Calculate latency
        latency_ms = (time.perf_counter() - start_time) * 1000
        self.frame_times.append(latency_ms)
        
        return frame
    
    def process_frame(self, frame: np.ndarray) -> None:
        """Simulate frame processing (gaze detection placeholder)"""
        # Simulate some basic processing
        # In real implementation, this would be gaze detection
        
        # Convert to grayscale (simulate processing)
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # Simulate face detection (lightweight operation)
        # In real app, this would be MediaPipe or similar
        _ = cv2.resize(gray, (160, 120))  # Simulate downscaling for detection
    
    def run_benchmark(self, duration_seconds: int = 30):
        """Run performance benchmark"""
        print(f"\nüìä Starting {duration_seconds}-second benchmark...")
        print("‚è≥ Please wait while collecting performance data...\n")
        
        if not self.initialize():
            return
        
        start_time = time.time()
        frame_count = 0
        last_report_time = start_time
        
        # Performance tracking
        cpu_samples = []
        memory_samples = []
        latency_samples = []
        
        print("üìà Live Metrics (updates every 2 seconds):")
        print("-" * 50)
        
        try:
            while (time.time() - start_time) < duration_seconds:
                # Capture frame
                frame = self.capture_frame()
                if frame is None:
                    continue
                
                self.total_frames += 1
                frame_count += 1
                
                # Process frame (simulate work)
                self.process_frame(frame)
                
                # Get resource metrics
                resources = self.resource_monitor.get_metrics()
                self.metrics.cpu_percent = resources['cpu_percent']
                self.metrics.memory_mb = resources['memory_mb']
                
                # Update FPS
                elapsed = time.time() - start_time
                if elapsed > 0:
                    self.metrics.fps = frame_count / elapsed
                
                # Update latency
                if self.frame_times:
                    self.metrics.frame_latency_ms = np.mean(self.frame_times)
                
                # Adjust quality based on resources
                self._adjust_quality(self.metrics.cpu_percent, self.metrics.memory_mb)
                
                # Collect samples
                cpu_samples.append(self.metrics.cpu_percent)
                memory_samples.append(self.metrics.memory_mb)
                latency_samples.append(self.metrics.frame_latency_ms)
                
                # Print live stats every 2 seconds
                current_time = time.time()
                if current_time - last_report_time >= 2.0:
                    self._print_live_stats(elapsed)
                    last_report_time = current_time
                
                # Small delay to prevent CPU spinning
                time.sleep(0.001)
                
        except KeyboardInterrupt:
            print("\n‚ö† Benchmark interrupted by user")
            
        finally:
            self.cleanup()
            
            # Print final results
            self._print_final_results(cpu_samples, memory_samples, latency_samples)
    
    def _print_live_stats(self, elapsed: float):
        """Print live statistics during benchmark"""
        print(f"  [{int(elapsed):02d}s] "
              f"FPS: {self.metrics.fps:5.1f} | "
              f"CPU: {self.metrics.cpu_percent:5.1f}% | "
              f"RAM: {self.metrics.memory_mb:6.1f}MB | "
              f"Latency: {self.metrics.frame_latency_ms:5.1f}ms | "
              f"Res: {self.current_resolution}")
    
    def _print_final_results(self, cpu_samples, memory_samples, latency_samples):
        """Print final benchmark results with pass/fail indicators"""
        print("\n" + "="*60)
        print("üìä BENCHMARK RESULTS")
        print("="*60)
        
        # CPU Results
        if cpu_samples:
            cpu_avg = np.mean(cpu_samples)
            cpu_peak = np.max(cpu_samples)
            cpu_pass = cpu_avg < 15
            
            print(f"\nüñ•Ô∏è CPU Usage:")
            print(f"  Average: {cpu_avg:.1f}%")
            print(f"  Peak:    {cpu_peak:.1f}%")
            print(f"  Target:  <15%")
            print(f"  Status:  {'‚úÖ PASS' if cpu_pass else '‚ùå FAIL'}")
            
            if not cpu_pass:
                print(f"  ‚ö† CPU usage {cpu_avg - 15:.1f}% over target")
        
        # Memory Results
        if memory_samples:
            mem_avg = np.mean(memory_samples)
            mem_peak = np.max(memory_samples)
            mem_pass = mem_peak < 300
            
            print(f"\nüíæ Memory Usage:")
            print(f"  Average: {mem_avg:.1f} MB")
            print(f"  Peak:    {mem_peak:.1f} MB")
            print(f"  Target:  <300 MB")
            print(f"  Status:  {'‚úÖ PASS' if mem_pass else '‚ùå FAIL'}")
            
            if not mem_pass:
                print(f"  ‚ö† Memory usage {mem_peak - 300:.1f}MB over target")
        
        # Latency Results
        if latency_samples:
            lat_avg = np.mean(latency_samples)
            lat_p95 = np.percentile(latency_samples, 95)
            lat_pass = lat_p95 < 100
            
            print(f"\n‚è±Ô∏è Frame Latency:")
            print(f"  Average: {lat_avg:.1f} ms")
            print(f"  P95:     {lat_p95:.1f} ms")
            print(f"  Target:  <100 ms")
            print(f"  Status:  {'‚úÖ PASS' if lat_pass else '‚ùå FAIL'}")
            
            if not lat_pass:
                print(f"  ‚ö† Latency {lat_p95 - 100:.1f}ms over target")
        
        # Frame Statistics
        print(f"\nüìπ Frame Statistics:")
        print(f"  Total frames:   {self.total_frames}")
        print(f"  Dropped frames: {self.dropped_frames}")
        if self.total_frames > 0:
            drop_rate = (self.dropped_frames/self.total_frames)*100
            print(f"  Drop rate:      {drop_rate:.1f}%")
        print(f"  Average FPS:    {self.metrics.fps:.1f}")
        
        print("\n" + "="*60)
        
        # Overall Assessment
        all_pass = (cpu_samples and np.mean(cpu_samples) < 15 and 
                   memory_samples and np.max(memory_samples) < 300 and
                   latency_samples and np.percentile(latency_samples, 95) < 100)
        
        print("\nüìã OVERALL ASSESSMENT:")
        if all_pass:
            print("‚úÖ ALL PERFORMANCE TARGETS MET!")
            print("   Ready to promote to EVOLUTIONARY prototype")
        else:
            print("‚ö†Ô∏è SOME TARGETS NOT MET")
            print("   Consider optimization or Change Request for spec adjustment")
        
        print("\n" + "="*60)
    
    def cleanup(self):
        """Clean up resources"""
        if self.cap:
            self.cap.release()


def main():
    """Main entry point for the prototype"""
    print("="*60)
    print("EAGLEARN WEBCAM CAPTURE PROTOTYPE (HEADLESS)")
    print("Type: THROWAWAY (Exploration)")
    print("="*60)
    print("\nThis test will:")
    print("1. Capture webcam frames for 30 seconds")
    print("2. Measure CPU, RAM, and latency")
    print("3. Dynamically adjust quality if needed")
    print("4. Provide pass/fail assessment")
    
    # Create and run benchmark
    capture = HeadlessWebcamCapture(device_id=0)
    
    # Run 30-second benchmark
    capture.run_benchmark(duration_seconds=30)
    
    # Evidence summary
    print("\nüéØ EVIDENCE COLLECTED:")
    print("- Webcam capture feasibility: ‚úÖ Tested")
    print("- Resource usage metrics: ‚úÖ Measured")
    print("- Dynamic quality adjustment: ‚úÖ Functional")
    print("- Memory stability: ‚úÖ Monitored")
    
    print("\nüìä DECISION POINT:")
    print("- If PASS: Proceed with gaze estimation implementation")
    print("- If FAIL: Optimize algorithms or adjust requirements via CR")


if __name__ == "__main__":
    main()